The Setup: Modeling ECMP and Congestion

The core objective of this assignment is to empirically demonstrate the performance limits of Static Hashing ECMP (Equal-Cost Multi-Path) routing within a theoretically non-blocking Fat-Tree topology. The model utilizes a Flow-Level Simulator built on the NetworkX library, focusing on load distribution rather than packet-level details. The Fat-Tree topology is constructed as an undirected graph (default K=4), ensuring full bisection bandwidth is available in aggregate. All physical links are modeled as Full-Duplex, meaning capacity is independent in both directions. Link capacity is normalized to 1.0 Unit Load. To maintain this distinction in the undirected graph, each link tracks traffic flow using two separate edge attributes: load_uv and load_vu, representing the accumulated load in each direction of the physical link.

A "Flow" is defined as a persistent demand for bandwidth between a source host (H_{src}) and a destination host (H_{dst}), quantified by a continuous demand value. The Total Demand is aggressively normalized and held constant across both the Success and Failure scenarios (set at 10 times Link Capacity) to ensure a fair comparison where the network is sufficiently challenged. This normalization guarantees that any observed congestion is due to the routing mechanism, not a simple lack of aggregate capacity.

The ECMP Hashing mechanism is implemented by identifying the ECMP Set (all shortest paths) between two hosts using nx.all_shortest_paths. The static hashing function is simplified to a uniform random selection from this set. In a real network, this selection is determined by a hash function operating on fields like the 5-tuple; our random choice serves as an abstract model of a statistically fair hash.

This setup successfully demonstrates the inherent problem in Fat-Trees and ECMP because it highlights the vulnerability of the hashing process. While the network is non-blocking in theory, the model shows that a significant number of large flows (Elephant Flows)—even when generated with high entropy inputs—can overwhelm a single path if the hash function maps them to the same path segment via a natural collision, resulting in severe congestion on that specific link while other equivalent links remain underutilized.

The Parameters: Traffic Patterns for ECMP Simulation

Here are the specific parameters and traffic patterns used to model the contrasting scenarios (Success A and Failure B) in the ECMP simulation. Both scenarios use a Fat-Tree topology with $K=4$ (Total 16 hosts) and a normalized Link Capacity of 1.0 Unit Load. The key difference lies in the distribution of flow demand and the resulting entropy of the hash input.

Scenario A: Success (Near-Perfect Load Balancing)This scenario is designed to utilize the Law of Large Numbers, demonstrating that ECMP works efficiently under statistically ideal conditions. We used a total of 1000 flows to ensure statistical randomness and smooth out imbalances. The Total Network Demand was set high at 10.0 Units, which ensures the network is challenged but the load is spread thinly across many flows. The flow size distribution was Uniform and Small, with each flow having an average demand of approximately 0.01 units. A 10% jitter was applied to each flow size to introduce slight randomness. Both source and destination hosts were chosen using a Uniform Random distribution, maximizing the diversity of hashing inputs (high entropy). This results in Load Balancing, where the uniform distribution of small flows prevents congestion.

![image_alt](https://github.com/OmriHanoch/ECMP/blob/2b6b183b7048de84b9e0e6380fd719652970fa9e/task2_1.png)

Scenario B: Failure (Congestion due to Low Entropy)This scenario is designed to induce hash collisions by concentrating the majority of the total demand into a few large flows with similar hashing inputs. The Total Number of Flows was kept at 1000, and the Total Network Demand was identical at 10.0 Units, proving that the failure is due to routing, not insufficient capacity. The flow size distribution was Bimodal, consisting of two types of flows. Elephant Flows (15% of the total, 150 flows) were the primary source of load, carrying 90% of the Total Demand (approx 9.0 Units). These large flows mean a single path collision is catastrophic. Mouse Flows (85% of the total, 850 flows) carried the remaining 10% of the demand, acting as background noise. For Hashing Input, both source and destination hosts for all Elephant Flows were chosen using a Uniform Random distribution (high entropy input). This setup increases the statistical probability that a critical number of high-demand flows will naturally map to the same core path segment via a random hash collision. The outcome is Congestion/Blocking, where the hash function maps the concentrated Elephant Flow demand onto a single core path segment, resulting in utilization far exceeding 100% on that specific link.

The Explanation:
The severe congestion observed in Scenario B, despite the network having the same total aggregate capacity as the successful Scenario A, is explained by the fundamental vulnerability of Static Hashing to low-entropy traffic patterns combined with highly imbalanced flow sizes.
In Scenario B, 90% of the total demand was carried by only 150 large Elephant Flows. Although both the source and destination for these flows were chosen randomly (high-entropy input), the sheer number of high-volume flows increased the statistical probability of a critical hash collision dramatically.
The failure occurred because the Static Hashing mechanism—which uses a deterministic function to map flows to one of the available equal-cost paths—is non-ideal:
Low Entropy Impact: When a large number of flows, even randomly chosen, pass through the same routing switch, the limited entropy provided by the standard hash function (which typically examines only a small portion of the 5-tuple) can result in similar hash outputs for different flows.
Critical Collision: This similarity caused a natural hash collision, forcing a critical mass of the high-demand Elephant Flows onto the same single core path segment.
